[
["index.html", "R for Social Science Prerequisites Outline", " R for Social Science Josiah Parry 2018-12-29 Prerequisites R is installed Working knowledge of basic algebra you know what PEMDAS stands for you know what substitution is i.e. solve for y when y = 3x - 3, and x = 1 Working knowledge of basic statistics mean, median, mode you kind of remember what a t-test is and what a p-value is Working knowledge of basic computer science principles logical values / statements (i.e. true, false, true and false, etc.) iteration If you feel iffy about any of that, a quick google search will help, or just send it and continue. Outline This outline will help me guide what I will write and cover. This is a list of the things that I think are important to know as a data scientist. the basics r as a calculator data types functions selecting object indexes tidyverse tibble selecting filter grouping summarising plotting reshaping presenting (Rmd) data visualization univariate histogram density plot (pmf / cmf) violin plot boxplot multivariate scatter plot (2 numeric) bar plot (1 nominal 1 numeric) boxplot (1 nominal 1 numeric) violin plot (1 nominal 1 numeric) map making (GIS) projections coordinate reference systems vector data shapefiles sf package oh looks, its a dataframe making the map density maps point density kernel density statistical modeling (machine learning) supervised learning Linear Regression (continuous prediction) evaluation: R^2, MSE, RMSE, MAE Logistic Regression (classification) evaluation: confusion matrix, auc, roc data preprocessing cross validation (k-fold) train, test, validate scaling &amp; centering (standardization) normalization imputation dimensionality reduction pca / lda backward feature selection supervised continued k-nearest neighbors Support Vector Machines (classification) Naive bayes (classification) random forest (regression / classification) gradient boosted trees (regression / classification) Unsupervised learning hierarchical clustering (classification) k-means neural networks natual language processing / text mining "],
["intro.html", "Chapter 1 The Basics 1.1 Arithmetic Operators 1.2 Creating Variables 1.3 Logical operators 1.4 Data Types! 1.5 Data Structures 1.6 Recap 1.7 HW", " Chapter 1 The Basics This section will go over the different types of data that we will use in R. Before we get into that, we need to know the basic workings of R. We can use R like a calculator. To be honest, everything that follows might be better learned from DataCamp’s Free Introduction to R. But if you’re still with me, I’m going to go over this stuff kind of quickly. 1.1 Arithmetic Operators ^ : exponentiation (exponents) [E] * : multiplication [M] / : division [D] + : addition [A] - : subtraction [S] These can be used together in parentheses [P] ( ) to determine the order of operations (PEMDAS) 2 ^ 2 ## [1] 4 2 * 3 ## [1] 6 4 / 2 ## [1] 2 1 + 3 ## [1] 4 3 - 2 ## [1] 1 1.2 Creating Variables So, as I said, knowledge of substition is a prerequisite. We can create new variables in our R environment (what’s an environment you ask?) that can be used to reference things. There are many types of variables, but will get into that later. Let’s work with something we’re all familiar with x. Note: I will use the words variable and object interchangeably throughout this. Say we want to solve y = 3x + 2 for when x = 5. We can create a variable for x and then make one for y. We create variables with the assignment operator/arrow, &lt;-. Mr. Jared Lander taught me that x &lt;- 1 formally reads as _“x gets 1”. To me, it just means they are set equal, like an equation. # This is a comment. This won&#39;t be run by R. x &lt;- 1 # You can print the variable by just writing it x ## [1] 1 Now let’s try some math with the variable. x * 3 ## [1] 3 x + 2 ## [1] 3 Alright, you’re getting the idea. How about using our formula above? 3 * x + 2 ## [1] 5 Okay, now lets create a new object called, y, which is the output of the above operation. y &lt;- 3 * x + 2 Here, y takes on the value of whatever is to the right of it. This is the case whenever you assign any object. 1.3 Logical operators Alright, this might get a little tricky, and if you struggle try cheking out section 5.2.2 of R for Data Science. &lt; : less than &gt; : greater than &lt;= : less than or equal to &gt;= : greater than or equal to == : exactly equal (I like to think of it as “are these the same thing?”) != : not equal ( “are these things not the same”) Let’s bring it back to early algebra. Let’s say x = 3 and y = 5. Is x less than y? # set variables. x &lt;- 3 y &lt;- 5 x &lt; y ## [1] TRUE # greater than? x &gt; y ## [1] FALSE # less than or equal x &lt;= y ## [1] TRUE # greater or equal x &gt;= y ## [1] FALSE # exactly equal? x == y ## [1] FALSE # not equal x != y ## [1] TRUE Alright, so now I want to talk about the ! (called the bang operator) and its nuance. See how we put ! in front of our =? The bang operator essentially checks the opposite of a thing. So in this case it checked the opposite of equals. If we put ! in front of a logical statement, it will reverse the outcome. 1 == 1 ## [1] TRUE !(1 == 1) ## [1] FALSE Now I want to introduce two more logical operators, and (&amp;), and or (|). &amp; checks multiple conditions and will return TRUE only if they are both TRUE. | will return TRUE when one of the conditions is TRUE. Now for an illustrative example for &amp; statements : # We have TRUE and TRUE, this should be false because they aren&#39;t both TRUE TRUE &amp; FALSE ## [1] FALSE # both a TRUE, we expect TRUE TRUE &amp; TRUE ## [1] TRUE # The first statement is TRUE, but the second is not TRUE, expect FALSE (1 == 1) &amp; (1 &lt; 1) ## [1] FALSE # The first statement is TRUE and the second is TRUE, expect TRUE (1 == 1) &amp; (1 &lt;= 1) ## [1] TRUE Illustrative | statements: Remember, only one condition needs to be TRUE. TRUE | TRUE ## [1] TRUE TRUE | FALSE ## [1] TRUE FALSE | FALSE ## [1] FALSE 1.4 Data Types! Okay! Now you’ve got an idea of the basics of R, maybe you’ve event caught on to some types of Data. There are 4 types of data that you will encounter on a regular basis. You’ve encountered 2 of them already. So, think back to your Stat 101 class. You dealt with discrete, continuous, and nominal data. Discrete data was whole numbers, or integers. Continuous data had decimal points. And nominal data was essentially just words. In R we will use: integer: discrete numeric: continuous character: nominal logical To indicate to R that a number is an integer we put an L after the number (why?). We can always check an object’s type by using the function class(). I’ll go over functions briefly later, but you should be able to pick up the intuition—tl;dr, functions take an input and make an output. # numbers are by default &quot;numeric&quot; class(2) ## [1] &quot;numeric&quot; # to specify an integer we can use the `L` class(2L) ## [1] &quot;integer&quot; character data is anything surrounded by quotations. Generally, these are things like words and sentences. my_characters &lt;- &quot;this is a character&quot; class(my_characters) ## [1] &quot;character&quot; You can’t add character objects to numerics (integers will be counted as a numeric, because they are a number). Most data types have a function to check if it is indeed that data type. You can check to see if a variable is a character by using the is.character() function. It will check the object’s class, and tell you if it matches with character. The output is a logical. logical data types are things like TRUE or FALSE. What is interesting is that TRUE is actually the value 1, and FALSE is actually 0. So you can add TRUE to a number. Funny, huh? TRUE + 5 ## [1] 6 Well, that just about covers the data types we will use. Now, it’s not often that we’ll just want to use 1 number or value for our work. Let’s get into data structures. 1.5 Data Structures 1.5.1 Vectors The simplest data structure in R is the vector. Vectors are “one-dimensional arrays”, that’s fancy speak for an object that holds many elements of the same type. So a vector will [almost] always be numeric (integer counts as numeric, remember?), character, or logical. We create vectors by using the function c(), which stands for combine. Each element of the vector is separated by a comma. c(1, 2) ## [1] 1 2 If you put a character (or a string, I will use both interchangeably from here on), in a numeric vector, R will coerce (force) the numbers to be treated like a character (meaning you can’t do math with them). c(1, 2, &quot;characters go here&quot;) ## [1] &quot;1&quot; &quot;2&quot; &quot;characters go here&quot; Notice how the numbers are in quotes now. So what happens when you put a logical inside a numeric? c(FALSE, 1, TRUE) ## [1] 0 1 1 See how that vector contains 3 elements, 0 1 1? Remember that that FALSE is actually a 0 and TRUE is a 1! Now, what if we want to tell R that there is missing data? We use NA to indicate missing data. c(1, 2, NA, 4) ## [1] 1 2 NA 4 Here is a fun shortcut: if you want to create a sequence of integers, you can use a :. If I wanted the numbers 1 through 20, I could write 1:20. my_ints &lt;- 1:20 my_ints # this prints it, remember? ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 We know that there are 20 elements in this vector, this means that the vector has a length of 20. We can always find out how long (or how many elements are in) a vector by supplying the vector to the length() function. # how long is `my_ints`? length(my_ints) ## [1] 20 Ah, just as anticipated! Say we wanted to add 10 to each value, we could supply the variable name in a basic arithmetic statement. my_ints + 10 ## [1] 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Say we wanted to only have the 10th element from my_ints, how would we get it? I mean, we know it’s 10, but we can’t write out every value we want every time. We can access it through an index. Indexes are accessed using brackets immediately after the object that we want to access. my_ints[10] ## [1] 10 We can access multiple values in this vector by supplying a vector to our vectors index (think about that one for a second). To grab the 1st, 10th, and 20th element of our vector we would put a vector with the values 1, 10, 20 in our index. my_ints[c(1, 10, 20)] ## [1] 1 10 20 But since vectors can be stored in object, we can create a vector called index and substitute that! # create an index vector index &lt;- c(1, 10, 20) # use that index to select from our vector my_ints[index] ## [1] 1 10 20 Many of you are probably quite familiar with Excel for doing your number crunching. The table look with columns and rows is a very useful way of visualizing and handling data. In R, we use something called data frames to do this. 1.5.2 data frames Unlike vectors, data frames are two-dimensional. I like to think of making a graph back in school where I’d know the x and y coordinates. We can think of our rows as x coordinates, and columns as y coordinates. Each coordinate pair makes a value pair in our data frame. Our two-dimensional data frames are actually made up of one-dimensional objects (vectors)! Say we have two vectors x and y. x &lt;- 1:10 y &lt;- 10:1 x ## [1] 1 2 3 4 5 6 7 8 9 10 y ## [1] 10 9 8 7 6 5 4 3 2 1 Notice how they are the same length! We can think of each element (observation) as one row. These vectors will become our columns in our data frame. Data frames can be constructed with data.frame(). The first argument (value) will be the vector which will become a column, and each preceding argument (separated with a comma) will be another column. df &lt;- data.frame(x, y) df ## x y ## 1 1 10 ## 2 2 9 ## 3 3 8 ## 4 4 7 ## 5 5 6 ## 6 6 5 ## 7 7 4 ## 8 8 3 ## 9 9 2 ## 10 10 1 Look at how nice that is! So, remember how we accessed values from vectors using [] and a value(s)? To get values from a data frame, we need to supply the brackets with x, y coordinates! This is because a data frame is two-dimensional, whereas the vector was 1 dimensional. If we want to get the first value from our x column, we need to specify that we want row (x) 1, and column (y) 1. Generally, this looks like df[x,y]. df[1,1] ## [1] 1 If we want to get whole rows, we leave the value in the column area empty (but remember the comma!). df[1,] ## x y ## 1 1 10 Now the same rule of thumb applies for columns, just leave the x value empty, but remember the comma. df[,1] ## [1] 1 2 3 4 5 6 7 8 9 10 Additionally, we can access the underlying columns another way, by using the $ operator. To do this we would write the data frame name, followed by $ and the column name, i.e. data_frame$col_name. To grab the x column of df we can do it like. df$x ## [1] 1 2 3 4 5 6 7 8 9 10 We can do math with our columns too! df$x * df$y ## [1] 10 18 24 28 30 30 28 24 18 10 1.6 Recap Alright, there are a few key take aways here. We can use R to do some math We can create variables which take on values we can even do math on those variables We can compare objects and values using logical statements We can store many values of the same type in one-dimensional vectors We can make two-dimensional tables from multiple one-dimensional vectors 1.7 HW Create a vector called z which is the square root of each element of the vector y. Create a data frame called xyz which has 3 columns made from the vectors x, y, and z. Check to see if each value of the column x is greater than or equal to the corresponding value in the y column 1.7.1 HW Solutions # Create a vector z z &lt;- sqrt(y) # create a new data frame xyz &lt;- data.frame(x, y, z) # compare x and y xyz$x &gt;= xyz$y ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE "],
["introducing-the-tidyverse.html", "Chapter 2 Introducing the tidyverse 2.1 Selecting data 2.2 Filtering your data 2.3 Chaining functions 2.4 Creating / manipulating data", " Chapter 2 Introducing the tidyverse Data frames will be the basis for many analyses. A set of packages makes working with them exceptionally easy. This is called the tidyverse. For most of our data manipulation a package called dplyr (d[ata] - plier ) will be the go to. For reading our data readr. What is nice, though, is that we can download all of these packages together in what is called the tidyverse. When we load the tidyverse we load most of the packages associated with it. To do this run install.packages(&quot;tidyverse&quot;). Load the package by running library(tidyverse). Before we can get to working with data, we will have to bring it into our environment. The data will be coming from a project from The Guardian called “The Counted”. The Guardian describes it as follows. The Counted is a project by the Guardian – and you – working to count the number of people killed by police and other law enforcement agencies in the United States throughout 2015 and 2016, to monitor their demographics and to tell the stories of how they died. This dataset lives in the counted.csv file. csv stands for comma separated values. This means that each value has a comma in between it letting us know when the next column begins. readr has a function called read_csv() which will take a csv and turn it into a dataframe for us to work with. # load tidyverse packages library(tidyverse) # read in the dataset counted &lt;- read_csv(&quot;data/the-counted/counted.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## age = col_double(), ## gender = col_character(), ## raceethnicity = col_character(), ## armed = col_character(), ## date = col_date(format = &quot;&quot;), ## streetaddress = col_character(), ## city = col_character(), ## state = col_character(), ## latitude = col_double(), ## longitude = col_double(), ## classification = col_character(), ## lawenforcementagency = col_character() ## ) counted ## # A tibble: 2,226 x 13 ## name age gender raceethnicity armed date streetaddress city ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Matt… 22 Male Black No 2015-01-01 1050 Carl Gr… Sava… ## 2 Lewi… 47 Male White Fire… 2015-01-02 4505 SW Mast… Aloha ## 3 Mich… 19 Male White No 2015-01-03 2600 Kaumual… Kaum… ## 4 John… 23 Male Hispanic/Lat… No 2015-01-03 500 North Ol… Wich… ## 5 Tim … 53 Male Asian/Pacifi… Fire… 2015-01-02 600 E Island… Shel… ## 6 Matt… 32 Male White Non-… 2015-01-04 630 Valencia… San … ## 7 Kenn… 22 Male Hispanic/Lat… Fire… 2015-01-05 E Knox Rd an… Chan… ## 8 Mich… 39 Male Hispanic/Lat… Other 2015-01-05 818 31st St Evans ## 9 Patr… 25 Male White Knife 2015-01-06 800 Howard St Stoc… ## 10 Bria… 26 Male Black No 2015-01-06 1618 E 123rd… Los … ## # ... with 2,216 more rows, and 5 more variables: state &lt;chr&gt;, ## # latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, classification &lt;chr&gt;, ## # lawenforcementagency &lt;chr&gt; 2.1 Selecting data In the last section we went over how to select individual columns using the $ symbol and using bracket notation. Those methods can become quite cumbersome to work with. dplyr provides an alternative method for selecting individual columns. For this we can use the select() function. select() works quite intuitively. The first argument to the function is the dataframe which you select from. Every subsequent argument is the name or position of a column. Note: The first argument for [almost] every function in the tidyverse is the data. This will be very helpful to remember when we start using the pipe %&gt;%. Say we wanted to select the name of every person killed in 2015 and 2016. This is quite simple. select(counted, name) ## # A tibble: 2,226 x 1 ## name ## &lt;chr&gt; ## 1 Matthew Ajibade ## 2 Lewis Lembke ## 3 Michael Kocher Jr ## 4 John Quintero ## 5 Tim Elliott ## 6 Matthew Hoffman ## 7 Kenneth Buck ## 8 Michael Rodriguez ## 9 Patrick Wetter ## 10 Brian Pickett ## # ... with 2,216 more rows Using the same notation we can select multiple columns. For example for name and age. The order that you select columns affects the order in which they appear in your output. As I put name first followed by age, the first column is name. select(counted, name, age) ## # A tibble: 2,226 x 2 ## name age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Matthew Ajibade 22 ## 2 Lewis Lembke 47 ## 3 Michael Kocher Jr 19 ## 4 John Quintero 23 ## 5 Tim Elliott 53 ## 6 Matthew Hoffman 32 ## 7 Kenneth Buck 22 ## 8 Michael Rodriguez 39 ## 9 Patrick Wetter 25 ## 10 Brian Pickett 26 ## # ... with 2,216 more rows Simple enough? Try it out. Try selecting age, state, armed, and lawenforcementagency. Solution: select(counted, age, state, armed, lawenforcementagency) ## # A tibble: 2,226 x 4 ## age state armed lawenforcementagency ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 22 GA No Chatham County Sheriff&#39;s Office ## 2 47 OR Firearm Washington County Sheriff&#39;s Office ## 3 19 HI No Kauai Police Department ## 4 23 KS No Wichita Police Department ## 5 53 WA Firearm Mason County Sheriff&#39;s Office ## 6 32 CA Non-lethal firearm San Francisco Police Department ## 7 22 AZ Firearm Chandler Police Department ## 8 39 CO Other Evans Police Department ## 9 25 CA Knife Stockton Police Department ## 10 26 CA No Los Angeles County Sheriff&#39;s Department ## # ... with 2,216 more rows 2.2 Filtering your data Remember those logical statements in the last section? Those will be very useful now. We can constrain our dataset under a set of criteria to return a subset of the original data frame. We can use our existing knowledge of vectors and data frames to create a subset of the data. Using our knowledge of logical vectors and bracket subsets, we can somewhat easily find all of the 20 year olds in our dataset. A solution to this would require us to create a logical vector to indicate the rows where the age is 20. Then we would have to supply that vector as an index to our dataframe to get our desired result. It would look like this: index &lt;- counted$age == 20 counted[index,] ## # A tibble: 50 x 13 ## name age gender raceethnicity armed date streetaddress city ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Jani… 20 Female Black Knife 2015-02-19 Bellefonte Dr Char… ## 2 &lt;NA&gt; NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA &lt;NA&gt; &lt;NA&gt; ## 3 Shaq… 20 Male Black Fire… 2015-03-02 1st Ave and … Joli… ## 4 Euge… 20 Male White Fire… 2015-03-17 13710 US Hwy… Onal… ## 5 Jami… 20 Male White Other 2015-03-19 Kneuman Rd Sumas ## 6 Todd… 20 Male Black Fire… 2015-04-24 1505 E Main … Trin… ## 7 Terr… 20 Male Black Other 2015-04-27 9500 Evergre… Detr… ## 8 Fera… 20 Male Arab-American No 2015-05-27 4600 E 15th … Long… ## 9 Tyro… 20 Male Black Fire… 2015-06-22 700 Saw Mill… Pitt… ## 10 Tyle… 20 Male White Fire… 2015-07-06 3300 SW 47th… Okla… ## # ... with 40 more rows, and 5 more variables: state &lt;chr&gt;, ## # latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, classification &lt;chr&gt;, ## # lawenforcementagency &lt;chr&gt; filter() allows us to do this in a simpler manner. The first argument (suprise) is the dataframe that will be subsetted. Every following argument is a logical statement that will be applied to the dataset. Whenever the logical statement returns TRUE that row will be returned as shown in the above base R code. filter(counted, age == 20) ## # A tibble: 34 x 13 ## name age gender raceethnicity armed date streetaddress city ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Jani… 20 Female Black Knife 2015-02-19 Bellefonte Dr Char… ## 2 Shaq… 20 Male Black Fire… 2015-03-02 1st Ave and … Joli… ## 3 Euge… 20 Male White Fire… 2015-03-17 13710 US Hwy… Onal… ## 4 Jami… 20 Male White Other 2015-03-19 Kneuman Rd Sumas ## 5 Todd… 20 Male Black Fire… 2015-04-24 1505 E Main … Trin… ## 6 Terr… 20 Male Black Other 2015-04-27 9500 Evergre… Detr… ## 7 Fera… 20 Male Arab-American No 2015-05-27 4600 E 15th … Long… ## 8 Tyro… 20 Male Black Fire… 2015-06-22 700 Saw Mill… Pitt… ## 9 Tyle… 20 Male White Fire… 2015-07-06 3300 SW 47th… Okla… ## 10 Fred… 20 Male Black Fire… 2015-07-12 5130 E Ponce… Ston… ## # ... with 24 more rows, and 5 more variables: state &lt;chr&gt;, ## # latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, classification &lt;chr&gt;, ## # lawenforcementagency &lt;chr&gt; Now, we can add another condition on to this function call to get all of the female twenty year olds. filter(counted, age == 20, gender == &quot;Female&quot;) ## # A tibble: 1 x 13 ## name age gender raceethnicity armed date streetaddress city ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Jani… 20 Female Black Knife 2015-02-19 Bellefonte Dr Char… ## # ... with 5 more variables: state &lt;chr&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, ## # classification &lt;chr&gt;, lawenforcementagency &lt;chr&gt; 2.3 Chaining functions The true power of the tidyverse comes from it’s ability to chain functions after eachother. This is all enabled by the forward pipe operator %&gt;%. The pipe operator takes the output of a function and provides that output as the first argument in the following function. You’ve seen how the first argument for every function here has been the data this is done purposefully to enable the use of the pipe. As always, the most helpful way to wrap your head around this is to see it in action. Let’s take one of the lines of code we used above and adapt it to use a pipe. We will select the name column of our data again. Previously we wrote select(data_frame, col_name). select(counted, name) ## # A tibble: 2,226 x 1 ## name ## &lt;chr&gt; ## 1 Matthew Ajibade ## 2 Lewis Lembke ## 3 Michael Kocher Jr ## 4 John Quintero ## 5 Tim Elliott ## 6 Matthew Hoffman ## 7 Kenneth Buck ## 8 Michael Rodriguez ## 9 Patrick Wetter ## 10 Brian Pickett ## # ... with 2,216 more rows counted %&gt;% select(name) ## # A tibble: 2,226 x 1 ## name ## &lt;chr&gt; ## 1 Matthew Ajibade ## 2 Lewis Lembke ## 3 Michael Kocher Jr ## 4 John Quintero ## 5 Tim Elliott ## 6 Matthew Hoffman ## 7 Kenneth Buck ## 8 Michael Rodriguez ## 9 Patrick Wetter ## 10 Brian Pickett ## # ... with 2,216 more rows This gets the basic point across but doesn’t adequately illustrate the power. So let’s combine filter() and select() to get the names of all 20 year olds in our dataset. To do this we will first filter our dataset, then pipe it to our the select function. counted %&gt;% filter(age == 20) %&gt;% select(name) ## # A tibble: 34 x 1 ## name ## &lt;chr&gt; ## 1 Janisha Fonville ## 2 Shaquille Barrow ## 3 Eugene Smith II ## 4 Jamison Childress ## 5 Todd Dye ## 6 Terrance Kellom ## 7 Feras Morad ## 8 Tyrone Harris ## 9 Tyler Rogers ## 10 Frederick Farmer ## # ... with 24 more rows glimpse(counted) ## Observations: 2,226 ## Variables: 13 ## $ name &lt;chr&gt; &quot;Matthew Ajibade&quot;, &quot;Lewis Lembke&quot;, &quot;Micha... ## $ age &lt;dbl&gt; 22, 47, 19, 23, 53, 32, 22, 39, 25, 26, 3... ## $ gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;... ## $ raceethnicity &lt;chr&gt; &quot;Black&quot;, &quot;White&quot;, &quot;White&quot;, &quot;Hispanic/Lati... ## $ armed &lt;chr&gt; &quot;No&quot;, &quot;Firearm&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Firearm&quot;, &quot;... ## $ date &lt;date&gt; 2015-01-01, 2015-01-02, 2015-01-03, 2015... ## $ streetaddress &lt;chr&gt; &quot;1050 Carl Griffin Dr&quot;, &quot;4505 SW Masters ... ## $ city &lt;chr&gt; &quot;Savannah&quot;, &quot;Aloha&quot;, &quot;Kaumakani&quot;, &quot;Wichit... ## $ state &lt;chr&gt; &quot;GA&quot;, &quot;OR&quot;, &quot;HI&quot;, &quot;KS&quot;, &quot;WA&quot;, &quot;CA&quot;, &quot;AZ&quot;,... ## $ latitude &lt;dbl&gt; 32.06669, 45.48747, 21.93335, 37.69380, 4... ## $ longitude &lt;dbl&gt; -81.16788, -122.89170, -159.64197, -97.28... ## $ classification &lt;chr&gt; &quot;Death in custody&quot;, &quot;Gunshot&quot;, &quot;Struck by... ## $ lawenforcementagency &lt;chr&gt; &quot;Chatham County Sheriff&#39;s Office&quot;, &quot;Washi... 2.4 Creating / manipulating data Within most datasets there are what are called latent variables. These are varibles that can be created by manipulating one or more columns. The way we create new columns in a tidy workflow is by using the mutate() function. This function allows us to assign column values directly or by manipulating existing columns. The argument structure for mutate() is quite simple. We first name the new column we are creating, then say it is equivalent to some statement. For example: counted %&gt;% mutate(x = 1) %&gt;% select(x) ## # A tibble: 2,226 x 1 ## x ## &lt;dbl&gt; ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 ## 7 1 ## 8 1 ## 9 1 ## 10 1 ## # ... with 2,216 more rows In this line of code we created a new column called x which is set to the value of 1 and then we select just that column. Next we will use mutate() and functions from the lubridate package to get the month, day, and year of the date of the individual’s death. As there is already a column called date which is of the date type (class(counted$date)) we can use the functions month(), day(), and year() from lubridate which return the integer corresponding with the date part we are trying to extract. library(lubridate) counted %&gt;% mutate(month = month(date), day = day(date), year = year(date)) %&gt;% # select date and our new columns select(date, month, day, year) ## # A tibble: 2,226 x 4 ## date month day year ## &lt;date&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2015-01-01 1 1 2015 ## 2 2015-01-02 1 2 2015 ## 3 2015-01-03 1 3 2015 ## 4 2015-01-03 1 3 2015 ## 5 2015-01-02 1 2 2015 ## 6 2015-01-04 1 4 2015 ## 7 2015-01-05 1 5 2015 ## 8 2015-01-05 1 5 2015 ## 9 2015-01-06 1 6 2015 ## 10 2015-01-06 1 6 2015 ## # ... with 2,216 more rows The new year column can be used to identify what year an individual was born. For this, we can subtract their age from the year of their death. Note we can use variables that were created in our mutate function call as we will do below. Since year was created in the mutate, our new birth_year variable must come after it. counted_age &lt;- counted %&gt;% mutate(month = month(date), day = day(date), year = year(date), birth_year = year - age) %&gt;% select(age, birth_year) counted_age ## # A tibble: 2,226 x 2 ## age birth_year ## &lt;dbl&gt; &lt;dbl&gt; ## 1 22 1993 ## 2 47 1968 ## 3 19 1996 ## 4 23 1992 ## 5 53 1962 ## 6 32 1983 ## 7 22 1993 ## 8 39 1976 ## 9 25 1990 ## 10 26 1989 ## # ... with 2,216 more rows "],
["aggregation.html", "Chapter 3 Aggregation", " Chapter 3 Aggregation count, group_by, summarise, "],
["visualization.html", "Chapter 4 Visualization", " Chapter 4 Visualization ggplot and stuff "],
["ok-but-where-gis.html", "Chapter 5 Ok, but where? (GIS)", " Chapter 5 Ok, but where? (GIS) coordinate reference systems, projections, shapefiles, vector data, raster, point density, yah. "],
["statistical-modelling-regression.html", "Chapter 6 statistical modelling (Regression)", " Chapter 6 statistical modelling (Regression) simple linear, multiple linear, logistic. "],
["data-preprocessing.html", "Chapter 7 Data preprocessing", " Chapter 7 Data preprocessing center, scale, standardize, normalize, cross validation, dimensionality reduction, feature selection "],
["supervised-learning.html", "Chapter 8 supervised learning", " Chapter 8 supervised learning knn, svm, nb, rf, xgb https://shirinsplayground.netlify.com/2018/11/ml_basics_gbm/ "],
["unsupervised-learning.html", "Chapter 9 Unsupervised learning", " Chapter 9 Unsupervised learning "],
["text-mining-natual-language-processing-nlp.html", "Chapter 10 text-mining / natual language processing (nlp)", " Chapter 10 text-mining / natual language processing (nlp) Honestly, just read tidy text text tokens stop words sentiment stemming "]
]
